---
title: "Seminar 6"
output: html_notebook
---

```{r}
library(sna)
library(igraph)
library(network)
library(intergraph)
library(NetCluster)
```

```{r}
load("advice_data_frame.Rdata")
load("friendship_data_frame.Rdata")
load("reports_to_data_frame.Rdata")
```

```{r}
head(advice_data_frame)
```

```{r}
head(friendship_data_frame)
```

```{r}
head(reports_to_data_frame)
```

Make an array of 3 the 3 data frames, add names to objects in list and check how many elements there are in our krack dataset

```{r}
krack <- list(advice_data_frame,
              friendship_data_frame,
              reports_to_data_frame)
graphs <- c('advice', 'friendship', 'reports')
names(krack) <- graphs
length(krack)
```

```{r}
names(krack)
```

```{r}
for (i in 1:length(krack)){
krack[[i]] <- as.matrix(krack[[i]])
}
```

```{r}
for(i in 1:3){
krack[[i]] <- subset(krack[[i]],
(krack[[i]][,3] > 0 ))
}
dim(krack[[1]]) # What is the size now?
```

```{r}
head(krack[[1]])
```

```{r}
for (i in 1:3){
krack[[i]] <- network(krack[[i]],
matrix.type = 'edgelist',
vertex.attr = list("AGE","TENURE","LEVEL","DEPT"),
vertex.attrnames = list("AGE","TENURE","LEVEL","DEPT"))
}
advice <- krack$advice
friendship <- krack$friendship
reports <- krack$reports
```

```{r}
friendship
```

```{r}
advice
```

```{r}
reports
```

Create a set of coordinates to run the plot in and plot networks

```{r}
n<-network.size(advice)
v1<-sample((0:(n-1))/n) #create a vector of random numbers
v2<-sample(v1)
x <- n/(2 * pi) * sin(2 * pi * v1)
y <- n/(2 * pi) * cos(2 * pi * v2)
mycoord <- cbind(x,y)
par(mar=c(0,0,1,0))
par(mfrow=c(1,3))
plot(advice, edge.col='azure4', vertex.col='darkorange',
     vertex.border='azure4',vertex.cex=2,coord=mycoord,
     main ='Advice')
plot(friendship, edge.col='azure4', vertex.col='darkorange',
     vertex.border='azure4',vertex.cex=2, coord=mycoord,
     main ='Friendship')
plot(reports, edge.col='azure4', vertex.col='darkorange',
     vertex.border='azure4',vertex.cex=2, coord=mycoord,
     main='Direct Reports')
```
Assignment task 1

1. Dyad census

```{r}
advice_dyad <- sna::dyad.census(advice)
friend_dyad <- sna::dyad.census(friendship)
reports_dyad <- sna::dyad.census(reports)
dyad_census <- rbind(advice_dyad, friend_dyad, reports_dyad)
row.names(dyad_census) <- c('advice', 'friendship', 'reports')
as.data.frame(dyad_census)
```

The networks are now positioned in a way to represented the networks from most to least connected, first being 'advice' and 'reports' being last

2. Centrality

a) Degrees
Creating igraph objects for further calculations

```{r}
advice_graph <- graph_from_data_frame(advice, directed = TRUE)
friend_graph <- graph_from_data_frame(friendship, directed = TRUE)
reports_graph <- graph_from_data_frame(reports, directed = TRUE)
```

```{r}
advice_indegree <- igraph::degree(advice_graph, mode = 'in')
advice_outdegree <- igraph::degree(advice_graph, mode = 'out')
advice_total <- igraph::degree(advice_graph, mode = 'total')
advices <- cbind(advice_indegree, advice_outdegree, advice_total)

friend_indegree <- igraph::degree(friend_graph, mode = 'in')
friend_outdegree <- igraph::degree(friend_graph, mode = 'out')
friend_total <- igraph::degree(friend_graph, mode = 'total')
friends <- cbind(friend_indegree, friend_outdegree, friend_total)

reports_indegree <- igraph::degree(reports_graph, mode = 'in')
reports_outdegree <- igraph::degree(reports_graph, mode = 'out')
reports_total <- igraph::degree(reports_graph, mode = 'total')
reports_d <- cbind(reports_indegree, reports_outdegree, reports_total)

as.data.frame(advices)
as.data.frame(friends)
as.data.frame(reports_d)
```

b) Betweenness

```{r}
advice_b <- igraph::betweenness(advice_graph)
friend_b <- igraph::betweenness(friend_graph)
reports_b <- igraph::betweenness(reports_graph)
all_betweenness <- cbind(advice_b, friend_b, reports_b)
colnames(all_betweenness) <- c('advice', 'friendship', 'reports')
as.data.frame(all_betweenness)
```

c) Closeness

```{r}
advice_closeness <- igraph::closeness(advice_graph, mode = 'all')
friend_closeness <- igraph::closeness(friend_graph, mode = 'all')
reports_closeness <- igraph::closeness(reports_graph, mode = 'all')
all_closeness <- cbind(advice_closeness, friend_closeness, reports_closeness)
colnames(all_closeness) <- c('advice', 'friendship', 'reports')
as.data.frame(all_closeness)
```

3. Triad census

```{r}
advice_triad <- sna::triad.census(advice)
friend_triad <- sna::triad.census(friendship)
reports_triad <- sna::triad.census(reports)
triad_census <- rbind(advice_triad, friend_triad, reports_triad)
row.names(triad_census) <- c('advice', 'friendship', 'reports')
as.data.frame(triad_census)
```

4. Transitivity

```{r}
#gtrans(dat, g=NULL, diag=FALSE, mode="digraph", measure = c("weak", 
 #   "strong", "weakcensus", "strongcensus", "rank", "correlation"), 
  #  use.adjacency = TRUE)

advice_weak <- gtrans(advice, mode = 'weak')
advice_strong <- gtrans(advice, mode = 'strong')
advice_weakcensus <- gtrans(advice, mode = 'weakcensus')
advice_strongcensus <- gtrans(advice, mode = 'strongcensus')
advice_rank <- gtrans(advice, mode = 'rank')
advice_corr <- gtrans(advice, mode = 'correlation')
advice_transitivity <- cbind(advice_weak, advice_strong, advice_weakcensus, advice_strongcensus, advice_rank, advice_corr)

fr_weak <- gtrans(friendship, mode = 'weak')
fr_strong <- gtrans(friendship, mode = 'strong')
fr_weakcensus <- gtrans(friendship, mode = 'weakcensus')
fr_strongcensus <- gtrans(friendship, mode = 'strongcensus')
fr_rank <- gtrans(friendship, mode = 'rank')
fr_corr <- gtrans(friendship, mode = 'correlation')
friend_transitivity <- cbind(fr_weak, fr_strong, fr_weakcensus, fr_strongcensus, fr_rank, fr_corr)

reports_weak <- gtrans(reports, mode = 'weak')
reports_strong <- gtrans(reports, mode = 'strong')
reports_weakcensus <- gtrans(reports, mode = 'weakcensus')
reports_strongcensus <- gtrans(reports, mode = 'strongcensus')
reports_rank <- gtrans(reports, mode = 'rank')
reports_corr <- gtrans(reports, mode = 'correlation')
reports_transitivity <- cbind(reports_weak, reports_strong, reports_weakcensus, reports_strongcensus, reports_rank, reports_corr)

as.data.frame(advice_transitivity)
as.data.frame(friend_transitivity)
as.data.frame(reports_transitivity)

all<-rbind(advice_transitivity, friend_transitivity, reports_transitivity)
colnames(all) <- c('weak', 'strong', 'weak census', 'strong census', 'rank', 'correlation')
row.names(all) <- c('advice', 'friendship', 'reports')
as.data.frame(all)
```

```{r}
formal <- as.matrix(read.csv('formal.csv', header = TRUE, row.names = 1))
roles <- read.csv('roles.csv', header = TRUE, row.names = 1)
formalnet <- network(formal)
par(mar=c(0,0,2,0))
indeg <- sna::degree(formalnet, cmode = 'indegree')
mycoord <- plot(formalnet, displaylabels=TRUE, edge.col='azure4',
vertex.col="#E41A1C", vertex.border='azure4',
vertex.cex = indeg + 1 , main ='Downton Abbey',
label.cex=0.5, label.pos = 5)
```

```{r}
orRule <- network(symmetrize(formalnet, rule='weak'),
directed = FALSE)
class(orRule)
```

```{r}
andRule <- network(symmetrize(formalnet, rule='strong'),
directed = FALSE)
```

```{r}
par(mar=c(1,1,2,1))
par(mfrow=c(1,3))
plot(formalnet, main = 'Original', coord=mycoord, vertex.cex =3,
edge.col='azure4', vertex.col="#E41A1C", vertex.border='azure4',
label=seq(1:20),label.pos=5,label.cex=.5,label.col='gray15')
plot(orRule, main = 'Or Rule', coord=mycoord, vertex.cex =3,
edge.col='azure4', vertex.col="#377EB8", vertex.border='azure4',
label=seq(1:20),label.pos=5,label.cex=.5,label.col='gray15')
plot(andRule, main = 'And Rule', coord=mycoord, vertex.cex =3,
edge.col='azure4', vertex.col="#4DAF4A", vertex.border='azure4',
label=seq(1:20),label.pos=5,label.cex=.5,label.col='gray15')
```

```{r}
snasymmformal <- orRule
aprioriformal<-blockmodel(snasymmformal, roles$commdetect,
block.content="density", mode="graph",
diag=FALSE)
heatmap(aprioriformal[[4]])
```

```{r}
aprioriformal[[1]]
aprioriformal[[2]]
aprioriformal[[3]]
aprioriformal[[4]]
```

```{r}
library(RColorBrewer)
par(mar=c(1,1,1,1),mfrow=c(2,3))
col5 <- brewer.pal(5, 'Set1')
cols <- ifelse(aprioriformal[[1]] == 1, col5[1],
ifelse(aprioriformal[[1]] == 2, col5[2],
ifelse(aprioriformal[[1]] == 3, col5[3],
ifelse(aprioriformal[[1]] == 4, col5[4], col5[5]))))
par(mar=c(1,1,2,1),mfrow=c(1,1))
plot(snasymmformal, main = 'Apriori Block Model', coord=mycoord,
vertex.cex =3, edge.col='azure4', vertex.col=cols,
vertex.border='azure4', label=seq(1:20), label.pos=5,
label.cex=.5, label.col='gray15')
```

```{r}
distformal <- dist(snasymmformal, method="euclidian", diag=FALSE)
thick <- as.vector(distformal)
par(mar=c(0.5,0,2,0))
plot(snasymmformal, main = 'Euclidean Distances', coord=mycoord,
vertex.cex =3, edge.col='azure4', vertex.col=col5[2],
vertex.border='azure4', label=seq(1:20),label.pos=5,
label.cex=.5,label.col='gray15', edge.lwd = thick^2)
```

```{r}
formalclust <- hclust(distformal, method="complete")
```

```{r}
exploratoryformal<-blockmodel(snasymmformal, formalclust, k=6,
block.content="density", mode="graph",
diag=FALSE)
par(mar=c(0,0,2,0))
plot.blockmodel(aprioriformal)
```

```{r}
plot.blockmodel(exploratoryformal)
```

Assignment 2
Experimenting with k

```{r}
exploratoryformal4<-blockmodel(snasymmformal, formalclust, k=4,
block.content="density", mode="graph",
diag=FALSE)
par(mar=c(0,0,2,0))
plot.blockmodel(exploratoryformal4)
```


```{r}
exploratoryformal2<-blockmodel(snasymmformal, formalclust, k=2,
block.content="density", mode="graph",
diag=FALSE)
par(mar=c(0,0,2,0))
plot.blockmodel(exploratoryformal2)
```

```{r}
exploratoryformal8<-blockmodel(snasymmformal, formalclust, k=8,
block.content="density", mode="graph",
diag=FALSE)
par(mar=c(0,0,2,0))
plot.blockmodel(exploratoryformal8)
```

```{r}
par(mar = c(1,1,4,1), mfrow = c(1,2))
heatmap(aprioriformal[[4]], main ='Apriori Blockmodel')
```

```{r}
heatmap(exploratoryformal[[4]], main ='Exploratory Blockmodel')
```

```{r}
connectedformal<-formal[-20,-20] # operation on the matrix
class(connectedformal)
```

```{r}
CONCOR <- function(mat, max.iter=1000, epsilon=1e-10){
mat <- rbind(mat, t(mat))
colN <- ncol(mat)
X <- matrix(rep(0, times=colN*colN), nrow=colN, ncol=colN)
target.abs.value <- colN * colN - epsilon
for (iter in 1:max.iter){
for(i in 1:colN){
for(j in i:colN){
X[i,j]<-cor(mat[,i], mat[,j], method=c("pearson"))
}
}
mat <- X+(t(X)-diag(diag((X))))
if (sum(abs(mat)) > target.abs.value) {
return(mat)
}
}
return(mat)
}
```

```{r}
rownames(connectedformal) <- row.names(roles)[1:19]
colnames(connectedformal) <- row.names(roles)[1:19]
```

```{r}
CONCORFORMAL<-CONCOR(connectedformal)
heatmap(CONCORFORMAL)
```

```{r}
part1 <- connectedformal[14:19,14:19]
colnames(part1)
```

```{r}
concor1 <- CONCOR(part1)
heatmap(concor1)
```

```{r}
part2 <- connectedformal[1:13,1:13] # isolate the first 13 nodes
# We commented the matrix out, but you can look at it on your own
##part2
concor2 <- CONCOR(part2) # Run through CONCOR
heatmap(concor2) # Look at the result
```

```{r}
part3<-c(1,3,8,9,12,13) # isolate the needed nodes
part3.1<-part2[part3,part3] # remove the isolates from partition 2
colnames(part3.1) # Who is here?
```

```{r}
part3.2 <- part2[-part3,-part3] # Extract remaining nodes from part2
concor3.2 <- CONCOR(part3.2) # Run it through CONCOR
heatmap(concor3.2)
```

```{r}
colnames(part3.2[1:2,1:2]) # Names in the first subpart
```

```{r}
colnames(part3.2[3:7,3:7]) # Names in the second subpart
```

```{r}
part3.2.2 <- part3.2[3:7,3:7] # Create a partition
```

Assignment 3
List partitions

```{r}
colnames(part1)
```

```{r}
colnames(part2)
```

```{r}
colnames(part3.1)
```

```{r}
colnames(part3.2)
```

```{r}
colnames(part3.2.2)
```

```{r}
load("friend_df.Rdata")
load("m182_full_data_frame.Rdata")
load("social_df.Rdata")
load("task_df.Rdata")
```

```{r}
m182_full_nonzero_edges <- subset(m182_full_data_frame,
(friend_tie > 0 | social_tie > 0 | task_tie > 0))
head( m182_full_nonzero_edges) # Check what's left
```

```{r}
m182_full <- graph.data.frame(m182_full_nonzero_edges)
summary(m182_full)
```

```{r}
m182_friend <- delete.edges(m182_full, E(m182_full)[E(m182_full)$friend_tie==0])
m182_social <- delete.edges(m182_full, E(m182_full)[E(m182_full)$social_tie==0])
m182_task <- delete.edges(m182_full, E(m182_full)[E(m182_full)$task_tie==0])
```

Assignment 4: why are we deleting edges?
We do not need edges with zero ties for blockmodeling

```{r}
# This is if we want to use the edge value
task_adjacency<-get.adjacency(m182_task, attr='task_tie')
# This is if we only want the tie (so it's 0 or 1)
binary_task_adjacency<-get.adjacency(m182_task)
```

```{r}
task_adjacency<-as.matrix(task_adjacency) #generate the matrix out of a graph
# Create a nx2n matrix of directed connections
task_matrix<-rbind(task_adjacency,t(task_adjacency))
```

```{r}
# Same for matrix of social connections:
social_adjacency<-get.adjacency(m182_social, attr='social_tie')
binary_social_adjacency<-get.adjacency(m182_social) #this is for later
social_adjacency<-as.matrix(social_adjacency)
social_matrix<-rbind(social_adjacency,t(social_adjacency))
# Because we want to analyze social and task connections together, bind matrices:
task_social_matrix <-rbind(task_matrix,social_matrix)
dim(task_social_matrix)
```

```{r}
task_social_cors<-cor(task_social_matrix) # Correlate matrices
```

```{r}
dissimilarity<-1-task_social_cors #subtract matrix values from 1
task_social_dist<-as.dist(dissimilarity) #create a distance matrix
```

```{r}
task_social_dist<-dist(t(task_social_matrix))
```

```{r}
task_social_hclust <- hclust(task_social_dist)
plot(task_social_hclust)
```

```{r}
cutree(task_social_hclust,k=2)
```

```{r}
clustered_observed_cors = vector() # set it as a vector
num_vertices = length(V(m182_task)) # get the length of the vector
```

```{r}
clustered_observed_cors <-clustConfigurations(num_vertices,task_social_hclust,task_social_cors)
```

```{r}
clustered_observed_cors$correlations
```

```{r}
num_clusters = 4 # Test our number of clusters
clusters <- cutree(task_social_hclust, k = num_clusters)
clusters
```

```{r}
cluster_cor_mat <- clusterCorr(task_social_cors,
clusters)
```

Assignment 5:
What rationale do you have for selecting the number of clusters / positions with the method above? 

It is generally more appropriate to select a smaller number of clusters, in this case we can look at the graph above and see that after a certain point correlation rises for only a bit, thus we choose. Experimenting with clustering with k less than 4 is not productive as 4 is the point where is the number correlation starts to rise gradually. As for choosing a number larger than 4: only some variance can be explained further so there is no need to test out many other cases. In our previous courses we usually used 3 >= k <= 7

```{r}
apriori = c(1, 2, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 3)
deductive_cluster_cor_mat <- generate_cluster_cor_mat(task_social_cors, apriori)
gcor(deductive_cluster_cor_mat, task_social_cors)
```

```{r}
# Blockmodel on valued task data
task_valued_blockmodel <- blockmodel(task_adjacency, clusters)
# Blockmodel on binary task data
binary_task_adjacency<-as.matrix(binary_task_adjacency) # turn graph to matrix first
task_binary_blockmodel <- blockmodel(binary_task_adjacency, clusters)
# Blockmodel on valued social data
social_valued_blockmodel <- blockmodel(social_adjacency, clusters)
#Blockmodel on binary social data
binary_social_adjacency<-as.matrix(binary_social_adjacency)
social_binary_blockmodel <- blockmodel(binary_social_adjacency, clusters)
# Now, look at the basic statistics:
task_mean <- mean(task_adjacency)
task_mean
```

```{r}
task_density <- graph.density(m182_task)
task_density
```

```{r}
social_mean <- mean(social_adjacency)
social_mean
```

```{r}
social_density <- graph.density(m182_social)
social_density
```

```{r}
plot1<-heatmap(task_valued_blockmodel[[4]])
```

```{r}
plot2 <- heatmap(social_valued_blockmodel[[4]])
```

```{r}
plot3 <- heatmap(task_binary_blockmodel[[4]])
```

```{r}
plot4 <- heatmap(social_binary_blockmodel[[4]])
```

Blockmodels help us characterise the data without making assumptions about it, examine it through a visual output


Homework 3

```{r}
load('trade.Rdata')
```

```{r}
head(trade.all)
```


```{r}
trade <- as.matrix(trade.all)
tradenet <- network(trade)
par(mar=c(0,0,2,0))
indeg <- sna::degree(tradenet, cmode = 'indegree')
mycoord <- plot(tradenet, displaylabels=TRUE, edge.col='azure4',
vertex.col="#E41A1C", vertex.border='azure4',
vertex.cex = indeg / 4, label.cex=0.5, label.pos = 5)
```

```{r}
orRuleTrade <- network(symmetrize(tradenet, rule='weak'),
directed = FALSE)
class(orRuleTrade)
```

```{r}
andRuleTrade <- network(symmetrize(tradenet, rule='strong'),
directed = FALSE)
```

```{r}
snasymmtrade <- orRuleTrade
disttrade <- dist(snasymmtrade, method="euclidian", diag=FALSE)
thick <- as.vector(disttrade)
tradeclust <- hclust(disttrade, method="complete")
exploratorytrade6<-blockmodel(snasymmtrade, tradeclust, k=6,
block.content="density", mode="graph",
diag=FALSE)
plot.blockmodel(exploratorytrade6)
```

```{r}
par(mar = c(1,1,4,1), mfrow = c(1,2))
heatmap(exploratorytrade6[[4]], main ='Exploratory Blockmodel')
```

```{r}
exploratorytrade4<-blockmodel(snasymmtrade, tradeclust, k=4,
block.content="density", mode="graph",
diag=FALSE)
plot.blockmodel(exploratorytrade4)
```

```{r}
par(mar = c(1,1,4,1), mfrow = c(1,2))
heatmap(exploratorytrade4[[4]], main ='Exploratory Blockmodel')
```

```{r}
exploratorytrade8<-blockmodel(snasymmtrade, tradeclust, k=8,
block.content="density", mode="graph",
diag=FALSE)
plot.blockmodel(exploratorytrade8)
```

```{r}
par(mar = c(1,1,4,1), mfrow = c(1,2))
heatmap(exploratorytrade6[[4]], main ='Exploratory Blockmodel')
```

```{r}
CONCOR <- function(mat, max.iter=1000, epsilon=1e-10){
mat <- rbind(mat, t(mat))
colN <- ncol(mat)
X <- matrix(rep(0, times=colN*colN), nrow=colN, ncol=colN)
target.abs.value <- colN * colN - epsilon
for (iter in 1:max.iter){
for(i in 1:colN){
for(j in i:colN){
X[i,j]<-cor(mat[,i], mat[,j], method=c("pearson"))
}
}
mat <- X+(t(X)-diag(diag((X))))
if (sum(abs(mat)) > target.abs.value) {
return(mat)
}
}
return(mat)
}
```

```{r}
connectedtrade<-trade[-24,-24]
class(connectedtrade)
```

```{r}
CONCORFORMAL<-CONCOR(connectedtrade)
heatmap(CONCORFORMAL)
```

